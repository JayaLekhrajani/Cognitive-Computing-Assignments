{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.optimizers import Adadelta, SGD, RMSprop, Adagrad, Adam, Adamax\n",
    "\n",
    "from keras.regularizers import l1_l2\n",
    "from keras.callbacks import EarlyStopping, Callback\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import logging\n",
    "from keras.layers import Activation, Dense\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler as SS\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(50000, 3072)\n",
    "x_test = x_test.reshape(10000, 3072)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Splitting dataset into training, validation and testing \n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_trn, X_val, y_trn, y_val = train_test_split(x_train, y_train, test_size=0.2,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes=10\n",
    "#y_trn = keras.utils.to_categorical(y_trn, num_classes)\n",
    "#y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "y_train=keras.utils.to_categorical(y_train, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_val = keras.utils.to_categorical(y_val, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_trn = keras.utils.to_categorical(y_trn, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 2,103,818\n",
      "Trainable params: 2,103,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Model 1\n",
    "from keras import optimizers\n",
    "\n",
    "# All parameter gradients will be clipped to\n",
    "# a maximum value of 0.5 and\n",
    "# a minimum value of -0.5.\n",
    "sgd = optimizers.SGD(lr=0.06, clipvalue=0.5,momentum=0.03, decay=0.01, nesterov=False)\n",
    "\n",
    "adam=keras.optimizers.Adamax(lr=0.02, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(512, activation='relu', input_shape=(3072,)))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(512, activation='relu'))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(512, activation='relu'))\n",
    "model1.add(Dropout(0.2))\n",
    "\n",
    "model1.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 17s - loss: 1.9328 - acc: 0.2977 - val_loss: 1.7938 - val_acc: 0.3625\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.8022 - acc: 0.3518 - val_loss: 1.7432 - val_acc: 0.3806\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.7706 - acc: 0.3621 - val_loss: 1.7171 - val_acc: 0.3891\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.7433 - acc: 0.3735 - val_loss: 1.6984 - val_acc: 0.3940\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 17s - loss: 1.7353 - acc: 0.3761 - val_loss: 1.6886 - val_acc: 0.3974\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.7196 - acc: 0.3842 - val_loss: 1.6764 - val_acc: 0.4012\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.7132 - acc: 0.3871 - val_loss: 1.6694 - val_acc: 0.4028\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 17s - loss: 1.7023 - acc: 0.3918 - val_loss: 1.6612 - val_acc: 0.4118\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.6999 - acc: 0.3927 - val_loss: 1.6557 - val_acc: 0.4109\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 17s - loss: 1.6938 - acc: 0.3915 - val_loss: 1.6532 - val_acc: 0.4133\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.6886 - acc: 0.3949 - val_loss: 1.6475 - val_acc: 0.4102\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.6843 - acc: 0.3946 - val_loss: 1.6440 - val_acc: 0.4160\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.6811 - acc: 0.3982 - val_loss: 1.6398 - val_acc: 0.4173\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.6769 - acc: 0.4019 - val_loss: 1.6352 - val_acc: 0.4189\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.6747 - acc: 0.4020 - val_loss: 1.6313 - val_acc: 0.4209\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.6702 - acc: 0.4042 - val_loss: 1.6297 - val_acc: 0.4211\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.6655 - acc: 0.4044 - val_loss: 1.6260 - val_acc: 0.4234\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.6633 - acc: 0.4095 - val_loss: 1.6232 - val_acc: 0.4254\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.6631 - acc: 0.4084 - val_loss: 1.6225 - val_acc: 0.4235\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.6591 - acc: 0.4105 - val_loss: 1.6195 - val_acc: 0.4240\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.6566 - acc: 0.4081 - val_loss: 1.6165 - val_acc: 0.4260\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.6569 - acc: 0.4095 - val_loss: 1.6154 - val_acc: 0.4256\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.6559 - acc: 0.4079 - val_loss: 1.6139 - val_acc: 0.4278\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.6534 - acc: 0.4088 - val_loss: 1.6129 - val_acc: 0.4265\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.6524 - acc: 0.4120 - val_loss: 1.6108 - val_acc: 0.4292\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.6487 - acc: 0.4115 - val_loss: 1.6084 - val_acc: 0.4294\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.6474 - acc: 0.4118 - val_loss: 1.6076 - val_acc: 0.4300\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.6462 - acc: 0.4124 - val_loss: 1.6066 - val_acc: 0.4303\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.6454 - acc: 0.4105 - val_loss: 1.6051 - val_acc: 0.4337\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.6438 - acc: 0.4160 - val_loss: 1.6035 - val_acc: 0.4336\n"
     ]
    }
   ],
   "source": [
    "history1 = model1.fit(X_trn, y_trn,\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_losses, train_accs = [], []\n",
    "val_losses, val_accs = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "  512/40000 [..............................] - ETA: 15s - loss: 1.5433 - acc: 0.4570"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/src/conda3_runtime.v18/4.1.1/lib/python3.5/site-packages/keras/models.py:851: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 17s - loss: 1.5845 - acc: 0.4340 - val_loss: 1.5407 - val_acc: 0.4522\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.5851 - acc: 0.4340 - val_loss: 1.5399 - val_acc: 0.4527\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 17s - loss: 1.5814 - acc: 0.4384 - val_loss: 1.5402 - val_acc: 0.4530\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.5853 - acc: 0.4375 - val_loss: 1.5393 - val_acc: 0.4523\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.5841 - acc: 0.4336 - val_loss: 1.5396 - val_acc: 0.4528\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.5826 - acc: 0.4373 - val_loss: 1.5392 - val_acc: 0.4526\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.5839 - acc: 0.4368 - val_loss: 1.5388 - val_acc: 0.4533\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.5822 - acc: 0.4360 - val_loss: 1.5386 - val_acc: 0.4533\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.5833 - acc: 0.4370 - val_loss: 1.5386 - val_acc: 0.4537\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.5846 - acc: 0.4369 - val_loss: 1.5384 - val_acc: 0.4530\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.5800 - acc: 0.4394 - val_loss: 1.5388 - val_acc: 0.4520\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.5831 - acc: 0.4365 - val_loss: 1.5377 - val_acc: 0.4535\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.5813 - acc: 0.4379 - val_loss: 1.5377 - val_acc: 0.4532\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.5815 - acc: 0.4369 - val_loss: 1.5370 - val_acc: 0.4551\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.5815 - acc: 0.4382 - val_loss: 1.5372 - val_acc: 0.4548\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.5817 - acc: 0.4369 - val_loss: 1.5364 - val_acc: 0.4552\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.5821 - acc: 0.4394 - val_loss: 1.5363 - val_acc: 0.4545\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.5768 - acc: 0.4410 - val_loss: 1.5365 - val_acc: 0.4535\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.5785 - acc: 0.4383 - val_loss: 1.5360 - val_acc: 0.4550\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.5800 - acc: 0.4382 - val_loss: 1.5356 - val_acc: 0.4545\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.5788 - acc: 0.4371 - val_loss: 1.5351 - val_acc: 0.4552\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.5799 - acc: 0.4394 - val_loss: 1.5353 - val_acc: 0.4558\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.5790 - acc: 0.4371 - val_loss: 1.5350 - val_acc: 0.4559\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 17s - loss: 1.5810 - acc: 0.4371 - val_loss: 1.5347 - val_acc: 0.4556\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.5786 - acc: 0.4381 - val_loss: 1.5347 - val_acc: 0.4545\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.5775 - acc: 0.4401 - val_loss: 1.5346 - val_acc: 0.4546\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 17s - loss: 1.5804 - acc: 0.4373 - val_loss: 1.5341 - val_acc: 0.4554\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.5803 - acc: 0.4395 - val_loss: 1.5342 - val_acc: 0.4554\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.5764 - acc: 0.4378 - val_loss: 1.5337 - val_acc: 0.4560\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 16s - loss: 1.5753 - acc: 0.4375 - val_loss: 1.5335 - val_acc: 0.4559\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Invalid DISPLAY variable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-6b308512cfbb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m                   \u001b[1;34mu'#8EBA42'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m                   u'#FFB5B8']\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_plot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mto_plot\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"losses\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/src/conda3_runtime.v18/4.1.1/lib/python3.5/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mfigure\u001b[1;34m(num, figsize, dpi, facecolor, edgecolor, frameon, FigureClass, **kwargs)\u001b[0m\n\u001b[0;32m    525\u001b[0m                                         \u001b[0mframeon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mframeon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m                                         \u001b[0mFigureClass\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFigureClass\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 527\u001b[1;33m                                         **kwargs)\n\u001b[0m\u001b[0;32m    528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfigLabel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/src/conda3_runtime.v18/4.1.1/lib/python3.5/site-packages/matplotlib/backends/backend_qt4agg.py\u001b[0m in \u001b[0;36mnew_figure_manager\u001b[1;34m(num, *args, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[0mFigureClass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'FigureClass'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFigure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[0mthisFig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFigureClass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_figure_manager_given_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthisFig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/src/conda3_runtime.v18/4.1.1/lib/python3.5/site-packages/matplotlib/backends/backend_qt4agg.py\u001b[0m in \u001b[0;36mnew_figure_manager_given_figure\u001b[1;34m(num, figure)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mCreate\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnew\u001b[0m \u001b[0mfigure\u001b[0m \u001b[0mmanager\u001b[0m \u001b[0minstance\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mfigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \"\"\"\n\u001b[1;32m---> 53\u001b[1;33m     \u001b[0mcanvas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFigureCanvasQTAgg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mFigureManagerQT\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/src/conda3_runtime.v18/4.1.1/lib/python3.5/site-packages/matplotlib/backends/backend_qt4agg.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, figure)\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'FigureCanvasQtAgg: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[0mFigureCanvasQT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m         \u001b[0mFigureCanvasQTAggBase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mFigureCanvasAgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/src/conda3_runtime.v18/4.1.1/lib/python3.5/site-packages/matplotlib/backends/backend_qt4.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, figure)\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'FigureCanvasQt qt4: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[0m_create_qApp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;31m# Note different super-calling style to backend_qt5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/src/conda3_runtime.v18/4.1.1/lib/python3.5/site-packages/matplotlib/backends/backend_qt5.py\u001b[0m in \u001b[0;36m_create_qApp\u001b[1;34m()\u001b[0m\n\u001b[0;32m    136\u001b[0m                 \u001b[0mdisplay\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DISPLAY'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mdisplay\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m':\\d'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Invalid DISPLAY variable'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m             \u001b[0mqApp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mQtWidgets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQApplication\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Invalid DISPLAY variable"
     ]
    }
   ],
   "source": [
    "for e in range(30):\n",
    "\n",
    "        loss = model1.fit(X_trn, y_trn,\n",
    "                         batch_size=32,\n",
    "                         validation_data=(x_test, y_test),\n",
    "                         nb_epoch=30)\n",
    "\n",
    "        train_losses.append(loss.history[\"loss\"])\n",
    "        val_losses.append(loss.history[\"val_loss\"])\n",
    "        train_accs.append(loss.history[\"acc\"])\n",
    "        val_accs.append(loss.history[\"val_acc\"])\n",
    "\n",
    "        # Save experimental log\n",
    "        d_log = {}\n",
    "        d_log[\"experiment_name\"] = \"Model1\"\n",
    "        d_log[\"img_dim\"] = 32*32*3\n",
    "        d_log[\"batch_size\"] = 32\n",
    "        d_log[\"nb_epoch\"] = 30\n",
    "        d_log[\"train_losses\"] = train_losses\n",
    "        d_log[\"val_losses\"] = val_losses\n",
    "        d_log[\"train_accs\"] = train_accs\n",
    "        d_log[\"val_accs\"] = val_accs\n",
    "        d_log[\"optimizer\"] = SGD\n",
    "        # Add model architecture\n",
    "        json_string = json.loads(model1.to_json())\n",
    "        for key in json_string.keys():\n",
    "            d_log[key] = json_string[key]\n",
    "        list_color = [u'#E24A33',\n",
    "                  u'#348ABD',\n",
    "                  u'#FBC15E',\n",
    "                  u'#777777',\n",
    "                  u'#988ED5',\n",
    "                  u'#8EBA42',\n",
    "                  u'#FFB5B8']\n",
    "        plt.figure()\n",
    "        plt.ylabel(to_plot, fontsize=20)\n",
    "        if to_plot == \"losses\":\n",
    "            plt.yscale(\"log\")\n",
    "        if to_plot == \"accs\":\n",
    "            plt.ylim([0, 1.1])\n",
    "        plt.xlabel(\"Number of epochs\", fontsize=20)\n",
    "        plt.title(\"%s experiment\" % dataset, fontsize=22)\n",
    "        plt.legend(loc=\"best\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"./figures/Model1_results.png\" )\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.53350017071\n",
      "Test accuracy: 0.4559\n"
     ]
    }
   ],
   "source": [
    "score1 = model1.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score1[0])\n",
    "print('Test accuracy:', score1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 1024)              3146752   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 3,871,242\n",
      "Trainable params: 3,871,242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Model 2\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='relu', input_shape=(3072,)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#RMSprop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "40000/40000 [==============================] - 32s - loss: 2.3833 - acc: 0.0976 - val_loss: 2.3064 - val_acc: 0.0969\n",
      "Epoch 2/20\n",
      "40000/40000 [==============================] - 31s - loss: 2.3525 - acc: 0.1021 - val_loss: 2.2914 - val_acc: 0.1339\n",
      "Epoch 3/20\n",
      "40000/40000 [==============================] - 31s - loss: 2.3321 - acc: 0.1083 - val_loss: 2.2827 - val_acc: 0.1343\n",
      "Epoch 4/20\n",
      "40000/40000 [==============================] - 31s - loss: 2.3237 - acc: 0.1126 - val_loss: 2.2758 - val_acc: 0.1284\n",
      "Epoch 5/20\n",
      "40000/40000 [==============================] - 31s - loss: 2.3141 - acc: 0.1137 - val_loss: 2.2699 - val_acc: 0.1278\n",
      "Epoch 6/20\n",
      "40000/40000 [==============================] - 31s - loss: 2.3065 - acc: 0.1195 - val_loss: 2.2644 - val_acc: 0.1274\n",
      "Epoch 7/20\n",
      "40000/40000 [==============================] - 30s - loss: 2.2995 - acc: 0.1264 - val_loss: 2.2593 - val_acc: 0.1301\n",
      "Epoch 8/20\n",
      "40000/40000 [==============================] - 31s - loss: 2.2980 - acc: 0.1274 - val_loss: 2.2539 - val_acc: 0.1341\n",
      "Epoch 9/20\n",
      "40000/40000 [==============================] - 31s - loss: 2.2922 - acc: 0.1318 - val_loss: 2.2488 - val_acc: 0.1383\n",
      "Epoch 10/20\n",
      "40000/40000 [==============================] - 31s - loss: 2.2872 - acc: 0.1341 - val_loss: 2.2435 - val_acc: 0.1443\n",
      "Epoch 11/20\n",
      "40000/40000 [==============================] - 31s - loss: 2.2827 - acc: 0.1361 - val_loss: 2.2384 - val_acc: 0.1498\n",
      "Epoch 12/20\n",
      "40000/40000 [==============================] - 31s - loss: 2.2788 - acc: 0.1352 - val_loss: 2.2333 - val_acc: 0.1557\n",
      "Epoch 13/20\n",
      "40000/40000 [==============================] - 31s - loss: 2.2713 - acc: 0.1472 - val_loss: 2.2279 - val_acc: 0.1611\n",
      "Epoch 14/20\n",
      "40000/40000 [==============================] - 31s - loss: 2.2668 - acc: 0.1499 - val_loss: 2.2226 - val_acc: 0.1684\n",
      "Epoch 15/20\n",
      "40000/40000 [==============================] - 31s - loss: 2.2617 - acc: 0.1527 - val_loss: 2.2171 - val_acc: 0.1752\n",
      "Epoch 16/20\n",
      "40000/40000 [==============================] - 30s - loss: 2.2578 - acc: 0.1525 - val_loss: 2.2118 - val_acc: 0.1813\n",
      "Epoch 17/20\n",
      "40000/40000 [==============================] - 30s - loss: 2.2529 - acc: 0.1594 - val_loss: 2.2061 - val_acc: 0.1860\n",
      "Epoch 18/20\n",
      "40000/40000 [==============================] - 31s - loss: 2.2484 - acc: 0.1604 - val_loss: 2.2006 - val_acc: 0.1919\n",
      "Epoch 19/20\n",
      "40000/40000 [==============================] - 30s - loss: 2.2465 - acc: 0.1632 - val_loss: 2.1954 - val_acc: 0.1974\n",
      "Epoch 20/20\n",
      "40000/40000 [==============================] - 31s - loss: 2.2414 - acc: 0.1643 - val_loss: 2.1901 - val_acc: 0.2024\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_trn, y_trn,\n",
    "                    batch_size=25,\n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2.18801478119\n",
      "Test accuracy: 0.2002\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 2,103,818\n",
      "Trainable params: 2,103,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Model 3\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(512, activation='relu', input_shape=(3072,)))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Dense(512, activation='relu'))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Dense(512, activation='tanh'))\n",
    "\n",
    "model2.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "40000/40000 [==============================] - 6s - loss: 2.4415 - acc: 0.0950 - val_loss: 2.3824 - val_acc: 0.0958\n",
      "Epoch 2/40\n",
      "40000/40000 [==============================] - 5s - loss: 2.3974 - acc: 0.0996 - val_loss: 2.3465 - val_acc: 0.0966\n",
      "Epoch 3/40\n",
      "40000/40000 [==============================] - 5s - loss: 2.3681 - acc: 0.1003 - val_loss: 2.3235 - val_acc: 0.1046\n",
      "Epoch 4/40\n",
      "40000/40000 [==============================] - 5s - loss: 2.3527 - acc: 0.1045 - val_loss: 2.3076 - val_acc: 0.1197\n",
      "Epoch 5/40\n",
      "40000/40000 [==============================] - 5s - loss: 2.3364 - acc: 0.1135 - val_loss: 2.2959 - val_acc: 0.1328\n",
      "Epoch 6/40\n",
      "40000/40000 [==============================] - 5s - loss: 2.3277 - acc: 0.1152 - val_loss: 2.2870 - val_acc: 0.1377\n",
      "Epoch 7/40\n",
      "40000/40000 [==============================] - 5s - loss: 2.3207 - acc: 0.1175 - val_loss: 2.2800 - val_acc: 0.1444\n",
      "Epoch 8/40\n",
      "40000/40000 [==============================] - 5s - loss: 2.3160 - acc: 0.1193 - val_loss: 2.2740 - val_acc: 0.1489\n",
      "Epoch 9/40\n",
      "40000/40000 [==============================] - 5s - loss: 2.3087 - acc: 0.1240 - val_loss: 2.2689 - val_acc: 0.1522\n",
      "Epoch 10/40\n",
      "40000/40000 [==============================] - 5s - loss: 2.3041 - acc: 0.1241 - val_loss: 2.2643 - val_acc: 0.1545\n",
      "Epoch 11/40\n",
      "40000/40000 [==============================] - 5s - loss: 2.3018 - acc: 0.1253 - val_loss: 2.2601 - val_acc: 0.1571\n",
      "Epoch 12/40\n",
      "40000/40000 [==============================] - 5s - loss: 2.2932 - acc: 0.1337 - val_loss: 2.2561 - val_acc: 0.1603\n",
      "Epoch 13/40\n",
      "40000/40000 [==============================] - 5s - loss: 2.2909 - acc: 0.1342 - val_loss: 2.2524 - val_acc: 0.1649\n",
      "Epoch 14/40\n",
      "40000/40000 [==============================] - 5s - loss: 2.2889 - acc: 0.1367 - val_loss: 2.2488 - val_acc: 0.1685\n",
      "Epoch 15/40\n",
      "40000/40000 [==============================] - 5s - loss: 2.2859 - acc: 0.1393 - val_loss: 2.2453 - val_acc: 0.1732\n",
      "Epoch 16/40\n",
      "40000/40000 [==============================] - 5s - loss: 2.2804 - acc: 0.1430 - val_loss: 2.2419 - val_acc: 0.1774\n",
      "Epoch 17/40\n",
      "40000/40000 [==============================] - 5s - loss: 2.2796 - acc: 0.1399 - val_loss: 2.2386 - val_acc: 0.1821\n",
      "Epoch 18/40\n",
      "40000/40000 [==============================] - 5s - loss: 2.2766 - acc: 0.1437 - val_loss: 2.2354 - val_acc: 0.1844\n",
      "Epoch 19/40\n",
      "40000/40000 [==============================] - 5s - loss: 2.2705 - acc: 0.1494 - val_loss: 2.2322 - val_acc: 0.1876\n",
      "Epoch 20/40\n",
      "40000/40000 [==============================] - 5s - loss: 2.2693 - acc: 0.1482 - val_loss: 2.2291 - val_acc: 0.1916\n",
      "Epoch 21/40\n",
      "40000/40000 [==============================] - 6s - loss: 2.2659 - acc: 0.1548 - val_loss: 2.2261 - val_acc: 0.1939\n",
      "Epoch 22/40\n",
      "40000/40000 [==============================] - 5s - loss: 2.2622 - acc: 0.1552 - val_loss: 2.2231 - val_acc: 0.1978\n",
      "Epoch 23/40\n",
      "40000/40000 [==============================] - 5s - loss: 2.2622 - acc: 0.1563 - val_loss: 2.2201 - val_acc: 0.2003\n",
      "Epoch 24/40\n",
      "40000/40000 [==============================] - 5s - loss: 2.2572 - acc: 0.1599 - val_loss: 2.2172 - val_acc: 0.2043\n",
      "Epoch 25/40\n",
      "40000/40000 [==============================] - 5s - loss: 2.2551 - acc: 0.1614 - val_loss: 2.2143 - val_acc: 0.2066\n",
      "Epoch 26/40\n",
      "40000/40000 [==============================] - 5s - loss: 2.2533 - acc: 0.1600 - val_loss: 2.2115 - val_acc: 0.2092\n",
      "Epoch 27/40\n",
      "40000/40000 [==============================] - 5s - loss: 2.2475 - acc: 0.1669 - val_loss: 2.2087 - val_acc: 0.2124\n",
      "Epoch 28/40\n",
      "40000/40000 [==============================] - 5s - loss: 2.2472 - acc: 0.1679 - val_loss: 2.2059 - val_acc: 0.2133\n",
      "Epoch 29/40\n",
      "40000/40000 [==============================] - 5s - loss: 2.2435 - acc: 0.1689 - val_loss: 2.2032 - val_acc: 0.2154\n",
      "Epoch 30/40\n",
      "40000/40000 [==============================] - 5s - loss: 2.2413 - acc: 0.1702 - val_loss: 2.2005 - val_acc: 0.2169\n",
      "Epoch 31/40\n",
      "40000/40000 [==============================] - 5s - loss: 2.2369 - acc: 0.1710 - val_loss: 2.1979 - val_acc: 0.2187\n",
      "Epoch 32/40\n",
      "40000/40000 [==============================] - 8s - loss: 2.2359 - acc: 0.1732 - val_loss: 2.1952 - val_acc: 0.2210\n",
      "Epoch 33/40\n",
      "40000/40000 [==============================] - 9s - loss: 2.2353 - acc: 0.1752 - val_loss: 2.1926 - val_acc: 0.2234\n",
      "Epoch 34/40\n",
      "40000/40000 [==============================] - 9s - loss: 2.2299 - acc: 0.1768 - val_loss: 2.1900 - val_acc: 0.2254\n",
      "Epoch 35/40\n",
      "40000/40000 [==============================] - 9s - loss: 2.2268 - acc: 0.1795 - val_loss: 2.1875 - val_acc: 0.2274\n",
      "Epoch 36/40\n",
      "40000/40000 [==============================] - 9s - loss: 2.2254 - acc: 0.1807 - val_loss: 2.1849 - val_acc: 0.2293\n",
      "Epoch 37/40\n",
      "40000/40000 [==============================] - 9s - loss: 2.2255 - acc: 0.1804 - val_loss: 2.1824 - val_acc: 0.2303\n",
      "Epoch 38/40\n",
      "40000/40000 [==============================] - 9s - loss: 2.2214 - acc: 0.1837 - val_loss: 2.1800 - val_acc: 0.2307\n",
      "Epoch 39/40\n",
      "40000/40000 [==============================] - 9s - loss: 2.2183 - acc: 0.1848 - val_loss: 2.1775 - val_acc: 0.2322\n",
      "Epoch 40/40\n",
      "40000/40000 [==============================] - 9s - loss: 2.2168 - acc: 0.1845 - val_loss: 2.1751 - val_acc: 0.2335\n"
     ]
    }
   ],
   "source": [
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "history2 = model2.fit(X_trn, y_trn,\n",
    "                    batch_size=128,\n",
    "                    epochs=40,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2.17451163864\n",
      "Test accuracy: 0.2344\n"
     ]
    }
   ],
   "source": [
    "score2 = model2.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score2[0])\n",
    "print('Test accuracy:', score2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 2,103,818\n",
      "Trainable params: 2,103,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Model 4\n",
    "from keras import regularizers\n",
    "model3 = Sequential()\n",
    "model3.add(Dense(512, activation='relu', input_shape=(3072,),kernel_regularizer=regularizers.l2(0.01),\n",
    "                activity_regularizer=regularizers.l1(0.01)))\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(Dense(512, activation='relu'))\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(Dense(512, activation='tanh'))\n",
    "\n",
    "model3.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model3.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "40000/40000 [==============================] - 40s - loss: 2.3076 - acc: 0.1002 - val_loss: 2.3054 - val_acc: 0.1046\n",
      "Epoch 2/25\n",
      "40000/40000 [==============================] - 40s - loss: 2.3069 - acc: 0.1015 - val_loss: 2.3078 - val_acc: 0.1029\n",
      "Epoch 3/25\n",
      "40000/40000 [==============================] - 40s - loss: 2.3074 - acc: 0.0989 - val_loss: 2.3132 - val_acc: 0.0960\n",
      "Epoch 4/25\n",
      "40000/40000 [==============================] - 41s - loss: 2.3074 - acc: 0.1007 - val_loss: 2.3029 - val_acc: 0.1008\n",
      "Epoch 5/25\n",
      "14490/40000 [=========>....................] - ETA: 25s - loss: 2.3074 - acc: 0.0986"
     ]
    }
   ],
   "source": [
    "history3 = model3.fit(X_trn, y_trn,\n",
    "                    batch_size=30,\n",
    "                    epochs=25,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2.30294412384\n",
      "Test accuracy: 0.1\n"
     ]
    }
   ],
   "source": [
    "score3 = model3.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score3[0])\n",
    "print('Test accuracy:', score3[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Model 5\n",
    "from keras.constraints import maxnorm\n",
    "epochs = 28\n",
    "lrate = 0.014\n",
    "decay = lrate/epochs\n",
    "sgd_4 = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "model_4=Sequential()\n",
    "model_4.add(Dense(1024, activation='relu', input_shape=(3072,),kernel_constraint=maxnorm(3)))\n",
    "#model_j.add(Dense(1024, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model_4.add(Dropout(0.2))\n",
    "model_4.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model_4.add(Dropout(0.2))\n",
    "model_4.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 1024)              3146752   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 3,676,682\n",
      "Trainable params: 3,676,682\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_4.compile(loss='categorical_crossentropy', optimizer=sgd_4, metrics=['accuracy'])\n",
    "print(model_4.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 1024)              3146752   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 3,676,682\n",
      "Trainable params: 3,676,682\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model_4.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/28\n",
      "50000/50000 [==============================] - 52s - loss: 1.2683 - acc: 0.5464 - val_loss: 1.1830 - val_acc: 0.5854\n",
      "Epoch 2/28\n",
      "50000/50000 [==============================] - 53s - loss: 1.2617 - acc: 0.5491 - val_loss: 1.1821 - val_acc: 0.5880\n",
      "Epoch 3/28\n",
      "50000/50000 [==============================] - 52s - loss: 1.2566 - acc: 0.5497 - val_loss: 1.1582 - val_acc: 0.5945\n",
      "Epoch 4/28\n",
      "50000/50000 [==============================] - 53s - loss: 1.2509 - acc: 0.5529 - val_loss: 1.1601 - val_acc: 0.5932\n",
      "Epoch 5/28\n",
      "50000/50000 [==============================] - 53s - loss: 1.2452 - acc: 0.5544 - val_loss: 1.1482 - val_acc: 0.5953\n",
      "Epoch 6/28\n",
      "50000/50000 [==============================] - 52s - loss: 1.2428 - acc: 0.5558 - val_loss: 1.1351 - val_acc: 0.6026\n",
      "Epoch 7/28\n",
      "50000/50000 [==============================] - 52s - loss: 1.2321 - acc: 0.5620 - val_loss: 1.1372 - val_acc: 0.6009\n",
      "Epoch 8/28\n",
      "50000/50000 [==============================] - 52s - loss: 1.2311 - acc: 0.5576 - val_loss: 1.1203 - val_acc: 0.6058\n",
      "Epoch 9/28\n",
      "50000/50000 [==============================] - 53s - loss: 1.2274 - acc: 0.5627 - val_loss: 1.1162 - val_acc: 0.6122\n",
      "Epoch 10/28\n",
      "50000/50000 [==============================] - 51s - loss: 1.2208 - acc: 0.5640 - val_loss: 1.1268 - val_acc: 0.6070\n",
      "Epoch 11/28\n",
      "50000/50000 [==============================] - 53s - loss: 1.2131 - acc: 0.5668 - val_loss: 1.1099 - val_acc: 0.6111\n",
      "Epoch 12/28\n",
      "50000/50000 [==============================] - 53s - loss: 1.2091 - acc: 0.5691 - val_loss: 1.1077 - val_acc: 0.6142\n",
      "Epoch 13/28\n",
      "50000/50000 [==============================] - 53s - loss: 1.2030 - acc: 0.5687 - val_loss: 1.1147 - val_acc: 0.6122\n",
      "Epoch 14/28\n",
      "50000/50000 [==============================] - 52s - loss: 1.2031 - acc: 0.5718 - val_loss: 1.0955 - val_acc: 0.6168\n",
      "Epoch 15/28\n",
      "50000/50000 [==============================] - 52s - loss: 1.1924 - acc: 0.5745 - val_loss: 1.1030 - val_acc: 0.6173\n",
      "Epoch 16/28\n",
      "50000/50000 [==============================] - 52s - loss: 1.1944 - acc: 0.5749 - val_loss: 1.0813 - val_acc: 0.6195\n",
      "Epoch 17/28\n",
      "50000/50000 [==============================] - 53s - loss: 1.1829 - acc: 0.5780 - val_loss: 1.0806 - val_acc: 0.6247\n",
      "Epoch 18/28\n",
      "50000/50000 [==============================] - 53s - loss: 1.1818 - acc: 0.5790 - val_loss: 1.0757 - val_acc: 0.6305\n",
      "Epoch 19/28\n",
      "50000/50000 [==============================] - 53s - loss: 1.1769 - acc: 0.5788 - val_loss: 1.0681 - val_acc: 0.6274\n",
      "Epoch 20/28\n",
      "50000/50000 [==============================] - 52s - loss: 1.1721 - acc: 0.5815 - val_loss: 1.0656 - val_acc: 0.6264\n",
      "Epoch 21/28\n",
      "50000/50000 [==============================] - 52s - loss: 1.1716 - acc: 0.5840 - val_loss: 1.0528 - val_acc: 0.6352\n",
      "Epoch 22/28\n",
      "50000/50000 [==============================] - 52s - loss: 1.1639 - acc: 0.5864 - val_loss: 1.0683 - val_acc: 0.6301\n",
      "Epoch 23/28\n",
      "50000/50000 [==============================] - 54s - loss: 1.1639 - acc: 0.5841 - val_loss: 1.0467 - val_acc: 0.6398\n",
      "Epoch 24/28\n",
      "50000/50000 [==============================] - 52s - loss: 1.1537 - acc: 0.5867 - val_loss: 1.0512 - val_acc: 0.6374\n",
      "Epoch 25/28\n",
      "50000/50000 [==============================] - 53s - loss: 1.1521 - acc: 0.5880 - val_loss: 1.0428 - val_acc: 0.6348\n",
      "Epoch 26/28\n",
      "50000/50000 [==============================] - 52s - loss: 1.1520 - acc: 0.5886 - val_loss: 1.0407 - val_acc: 0.6418\n",
      "Epoch 27/28\n",
      "50000/50000 [==============================] - 52s - loss: 1.1453 - acc: 0.5912 - val_loss: 1.0347 - val_acc: 0.6456\n",
      "Epoch 28/28\n",
      "50000/50000 [==============================] - 52s - loss: 1.1406 - acc: 0.5920 - val_loss: 1.0265 - val_acc: 0.6461\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7fadd0e3c8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Fit the model\n",
    "#model_j.fit(X_trn, y_trn, validation_data=(X_val, y_val), epochs=epochs, batch_size=32)\n",
    "model_4.fit(x_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 55.28%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model_4.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5 (Experimental) with Spark 2.0",
   "language": "python",
   "name": "python3-spark20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
